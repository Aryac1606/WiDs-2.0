import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

#importing data
from google.colab import files
uploaded = files.upload()

df = pd.read_csv('tesla.csv')
print(df.columns.tolist())

import pandas as pd
import numpy as np


df = pd.read_csv('tesla.csv')

df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)

# inserting rows for any missing dates in the sequence
full_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='D')
df = df.reindex(full_range)

# Addressing Missing Values (Imputation)
# Forward Fill 
df_ffill = df.fillna(method='ffill')

# Save the main 'df'
df.to_csv('cleaned_financial_data.csv')

#dividing data
total_rows = len(df)
#t=decimal train ratio (70/80%)
train_ratio = 0.8
total_data = int(total_rows*train_ratio)
#for train
train = df.iloc[:total_data]
#for testing
test = df.iloc[total_data:]
#can use data for test

import matplotlib.pyplot as plt
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# We use the training data to determine parameters
fig, axes = plt.subplots(1, 2, figsize=(16, 4))

# Plot ACF
plot_acf(train['Close'], ax=axes[0])
axes[0].set_title('ACF Plot (to determine q)')

# Plot PACF
plot_pacf(train['Close'], ax=axes[1])
axes[1].set_title('PACF Plot (to determine p)')

plt.show()

from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
import matplotlib.pyplot as plt

# Ensure we are using the actual data column
# Replace 'Value' with your actual column name
data_to_plot = train['Close'].dropna()

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

# Explicitly setting lags to 20 to fix the x-axis scale
plot_acf(data_to_plot, lags=20, ax=ax1)
plot_pacf(data_to_plot, lags=20, ax=ax2)

plt.tight_layout()
plt.show()

from statsmodels.tsa.arima.model import ARIMA

# Using (p=1, d=1, q=1) as a very solid starting point for financial data
model = ARIMA(train['Close'], order=(1, 1, 1))
model_fit = model.fit()

print(model_fit.summary())

import itertools
from statsmodels.tsa.arima.model import ARIMA
import warnings
warnings.filterwarnings("ignore")

# 1. Identify the data column (using index 0 to avoid KeyError: 'Close')
train_data = train.iloc[:, 0]

# 2. GRID SEARCH: This creates the "optimal" parameters you were looking for
p = range(0, 3)
d = range(0, 2)
q = range(0, 3)
pdq_combinations = list(itertools.product(p, d, q))

best_aic = float("inf")
best_order = None

print("Searching for optimal (p, d, q)...")
for order in pdq_combinations:
    try:
        temp_model = ARIMA(train_data, order=order)
        temp_result = temp_model.fit()
        if temp_result.aic < best_aic:
            best_aic = temp_result.aic
            best_order = order
    except:
        continue

# 3. TRAIN: Now 'best_order' is defined and can be used to train the model
print(f"Optimal parameters found: {best_order}")

model = ARIMA(train_data, order=best_order)
model_fit = model.fit()

# 4. RESULTS
print(model_fit.summary())

import matplotlib.pyplot as plt

# 1. Generate the forecast for the length of the test set
# This provides both the mean prediction and confidence intervals
forecast_obj = model_fit.get_forecast(steps=len(test))
forecast_mean = forecast_obj.predicted_mean
conf_int = forecast_obj.conf_int()

# 2. Align the forecast index with your test data dates
forecast_mean.index = test.index
conf_int.index = test.index

plt.figure(figsize=(12, 6))

# Plot the last 200 days of training data for context (to see the transition)
plt.plot(train.index[-200:], train.iloc[-200:, 0], label='Training Data (Recent)', color='blue')

# Plot the Actual Observed Values from the test set
plt.plot(test.index, test.iloc[:, 0], label='Actual Observed Prices', color='black', linewidth=1.5)

# Plot the ARIMA Predicted Values
plt.plot(test.index, forecast_mean, label='ARIMA Forecast', color='red', linestyle='--')

# Plot the Confidence Interval (95%)
plt.fill_between(test.index, 
                 conf_int.iloc[:, 0], 
                 conf_int.iloc[:, 1], 
                 color='pink', alpha=0.3, label='95% Confidence Interval')

plt.title('FinSearch: Actual vs. Predicted Stock Prices (ARIMA 2,1,2)')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend(loc='upper left')
plt.grid(True, alpha=0.3)
plt.show()

from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np
import pandas as pd

# 1. Align actual and predicted values to handle any missing dates or NaNs
# We use the first column of the test set as 'actual'
comparison_df = pd.DataFrame({
    'actual': test.iloc[:, 0],
    'predicted': forecast_mean
}).dropna()

# 2. Calculate the metrics
mae = mean_absolute_error(comparison_df['actual'], comparison_df['predicted'])
mse = mean_squared_error(comparison_df['actual'], comparison_df['predicted'])
rmse = np.sqrt(mse)

# 3. Print the assessment report
print("--- ARIMA Model Performance Assessment ---")
print(f"Mean Absolute Error (MAE):      {mae:.2f}")
print(f"Mean Squared Error (MSE):      {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print("------------------------------------------")
print(f"Observations used for assessment: {len(comparison_df)}")

import matplotlib.pyplot as plt
import pandas as pd

# 1. Plot: Original Series, Test Data, and Forecast
plt.figure(figsize=(12, 6))

# Plot training and actual test data
plt.plot(train.index, train.iloc[:, 0], label='Training Data', color='blue', alpha=0.6)
plt.plot(test.index, test.iloc[:, 0], label='Actual Test Data (Observed)', color='black', linewidth=1.5)

# Plot Forecast and Confidence Intervals
forecast_obj = model_fit.get_forecast(steps=len(test))
forecast_mean = forecast_obj.predicted_mean
conf_int = forecast_obj.conf_int()

plt.plot(test.index, forecast_mean, label='ARIMA Forecast', color='red', linestyle='--')
plt.fill_between(test.index, conf_int.iloc[:, 0], conf_int.iloc[:, 1], color='pink', alpha=0.3, label='95% Confidence Interval')

plt.title('ARIMA Model: Original Data vs. Forecast')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend(loc='upper left')
plt.grid(True, alpha=0.3)
plt.show()

# 2. Plot: Residuals Analysis
# In-sample residuals (errors during training)
residuals = model_fit.resid

fig, ax = plt.subplots(1, 2, figsize=(15, 5))

# Time series plot of residuals
ax[0].plot(residuals, color='purple')
ax[0].axhline(0, color='black', linestyle='--', linewidth=1)
ax[0].set_title('Model Residuals over Time')
ax[0].set_ylabel('Error Value')
ax[0].grid(True, alpha=0.3)

# Histogram/Density of residuals
ax[1].hist(residuals, bins=50, color='purple', alpha=0.7, edgecolor='black')
ax[1].set_title('Distribution of Residuals')
ax[1].set_xlabel('Error Magnitude')
ax[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

